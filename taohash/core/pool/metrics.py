from dataclasses import dataclass

from taohash.core.pool.pool import PoolBase


@dataclass
class MiningMetrics:
    """
    Mining Metrics contain latest data about the miner's hashrate and shares.
    This is used by the validators to evaluate the miner's performance.
    Objects are populated by the validator's Pool API.
    """

    hotkey: str
    hash_rate_5m: float = 0.0  # In 5 minutes, hash rate in Gh/s
    hash_rate_60m: float = 0.0
    hash_rate_unit: str = "Gh/s"
    shares_5m: float = 0.0
    shares_60m: float = 0.0

    def __add__(self, other: "MiningMetrics") -> "MiningMetrics":
        """
        Adds two MiningMetrics objects together.
        """
        new = MiningMetrics(self.hotkey, hash_rate_unit="Th/s")

        for attr in ["hash_rate_5m", "hash_rate_60m"]:
            in_ths_self = getattr(self, attr) / 1000 if self.hash_rate_unit == "Gh/s" else getattr(self, attr)
            in_ths_other = getattr(other, attr) / 1000 if other.hash_rate_unit == "Gh/s" else getattr(other, attr)
            
            setattr(new, attr, in_ths_self + in_ths_other)

        for attr in ["shares_5m", "shares_60m"]:
            setattr(new, attr, getattr(self, attr) + getattr(other, attr))

        return new

    def get_value_last_5m(self, hash_price: float) -> float:
        """
        Estimates the value generated by the miner in the last 5 minutes.
        It takes into account:
            - Miner's hashrate provided in 5 minutes
            - Hash price in USD/TH/day
        Returns the estimated value in USD per 5 minutes.
        """
        hash_rate_th = (
            self.hash_rate_5m / 1000
            if self.hash_rate_unit == "Gh/s"
            else self.hash_rate_5m
        )
        # Value per day: hash_rate_th * hash_price (USD/TH/day)
        est_value_per_day = hash_rate_th * hash_price
        est_value_per_5m = est_value_per_day * (5 / 1440)  # 1440 mins per day
        return est_value_per_5m

    def get_value_last_day(self, hash_price: float) -> float:
        """
        Estimates the value generated by the miner in the last 24 hours.
        It takes into account:
            - Miner's hashrate provided in 60 minutes
            - Hash price in USD/TH/day
        Returns the estimated value in USD per day.
        """
        hash_rate_th = (
            self.hash_rate_60m / 1000
            if self.hash_rate_unit == "Gh/s"
            else self.hash_rate_60m
        )
        est_value_per_day = hash_rate_th * hash_price
        return est_value_per_day

    def get_value_past_hour(self, hash_price: float) -> float:
        """
        Estimates the value generated by the miner in the past hour.
        It takes into account:
            - Miner's hashrate provided in 60 minutes
            - Hash price in USD/TH/day
        Returns the estimated value in USD per hour.
        """
        hash_rate_th = (
            self.hash_rate_60m / 1000
            if self.hash_rate_unit == "Gh/s"
            else self.hash_rate_60m
        )
        est_value_per_day = hash_rate_th * hash_price
        est_value_per_hour = est_value_per_day * (1 / 24)
        return est_value_per_hour


def get_metrics_for_miner_by_hotkey(
    pool: PoolBase, hotkey_ss58: str, uid: int, coin: str
) -> MiningMetrics:
    """
    Retrieves the mining metrics for a given miner's hotkey.
    """
    shares = pool.get_hotkey_contribution(hotkey_ss58, uid, coin)
    return MiningMetrics(
        hotkey_ss58,
        shares["hash_rate_5m"],
        shares["hash_rate_60m"],
        shares["hash_rate_unit"],
        shares["shares_5m"],
        shares["shares_60m"],
    )

def _get_legacy_worker_id(hotkey: str) -> str:
    return hotkey[:4] + hotkey[-4:]

def get_metrics_for_miners(
    pool: PoolBase, hotkeys: list[str], uids: list[int], block_at_registration: list[int], coin: str
) -> list[MiningMetrics]:
    """
    Retrieves the mining metrics for all miners active in the validator's pool.
    """
    metrics = []
    all_workers = pool.get_all_miner_contributions(coin)

    ## Handle legacy worker ids; only use the oldest hotkey for each worker id
    hk_idx_to_legacy_metrics = {} # map hotkeys idx -> worker_metrics
    legacy_worker_ids = {} # map legacy_worker_id -> hotkey_idx
    for i, hotkey in enumerate(hotkeys):
        legacy_worker_id = _get_legacy_worker_id(hotkey)

        if legacy_worker_id in legacy_worker_ids:
            # Duplicate worker id, check how old the hotkey is
            other_hotkey_idx = legacy_worker_ids[legacy_worker_id]
            if block_at_registration[i] < block_at_registration[other_hotkey_idx]:
                # This hotkey is older, use this one
                # remove old entry
                del hk_idx_to_legacy_metrics[other_hotkey_idx]
            else:
                continue # This hotkey is newer, skip it
        
        # Add the hotkey to map
        legacy_worker_ids[legacy_worker_id] = str(i)
    
        worker_metrics_legacy = all_workers.get(legacy_worker_id, None)
        if worker_metrics_legacy is not None:
            hk_idx_to_legacy_metrics[str(i)] = worker_metrics_legacy

    ## Handle the new worker ids and incorporate the metrics from the legacy worker ids
    for i, hotkey in enumerate(hotkeys):
        worker_id = pool._get_worker_id_for_hotkey(hotkey, uids[i])
        legacy_worker_metrics = hk_idx_to_legacy_metrics.get(str(i), None)

        if worker_id is None and legacy_worker_metrics is None:
            metrics.append(MiningMetrics(hotkey))
            continue

        worker_metrics = all_workers.get(worker_id, None)
        if worker_metrics is None and legacy_worker_metrics is None:
            metrics.append(MiningMetrics(hotkey))
        else:
            metrics.append(
                MiningMetrics(
                    hotkey,
                    worker_metrics["hash_rate_5m"],
                    worker_metrics["hash_rate_60m"],
                    worker_metrics["hash_rate_unit"],
                    worker_metrics["shares_5m"],
                    worker_metrics["shares_60m"],
                ) + MiningMetrics(
                    hotkey,
                    legacy_worker_metrics["hash_rate_5m"],
                    legacy_worker_metrics["hash_rate_60m"],
                    legacy_worker_metrics["hash_rate_unit"],
                    legacy_worker_metrics["shares_5m"],
                    legacy_worker_metrics["shares_60m"],
                )
            )
    return metrics
